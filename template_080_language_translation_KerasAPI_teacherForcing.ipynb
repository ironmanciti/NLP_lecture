{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622b4637",
   "metadata": {
    "id": "Q15ChKHSG8y4"
   },
   "source": [
    "# 080. seq2seq language translation\n",
    "\n",
    "### Encoder-Decoder model\n",
    "\n",
    "\n",
    "- 영어-한국어 번역"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5dfff50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74eb9f93",
   "metadata": {
    "id": "_kawPBRbh6NO"
   },
   "source": [
    "한글 Glove file download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2002351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52bf040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c24f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49faaf66",
   "metadata": {
    "id": "88dOCLrOG8zA"
   },
   "source": [
    "## 입력 data list 작성  \n",
    "\n",
    "### 1. input_texts     : original language 의 input text  \n",
    "\n",
    "\n",
    "### 2. Teacher Forcing 용 input / target data 생성\n",
    "\n",
    "- target_texts_inputs  : 1 만큼 offset 된 target language sentence $\\rightarrow$ `<sos>....`  \n",
    "- target_texts  : target language sentence  $\\rightarrow$ `.....<eos>`\n",
    "\n",
    "\n",
    "\n",
    "- data 는 http://www.manythings.org/anki/  (Tab-delimited Bilingual Sentence Pairs) 에서 download  \n",
    "\n",
    "\n",
    "    - English(input) + `\\t` + The Other Language(target) + `\\t` + Attribution(기여자) 형식으로 구성\n",
    "        ex)\n",
    "        - Hi.\t안녕.\tCC-BY 2.0 (France) Attribution: tatoeba.org #538123 (CM) & #8355888 (Eunhee).\n",
    "        - I like horses.\t나는 말을 좋아해.\tCC-BY 2.0 (France) Attribution: tatoeba.org #1331062 (Kirschen112) & #8365125 (Eunhee)\n",
    "        - We had fun with Tom.\t우리는 톰과 즐거운 시간을 가졌다.\tCC-BY 2.0 (France) Attribution: tatoeba.org #6845055 (CK) & #6845295 (dalgarak)\n",
    "\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e9952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa04f8c7",
   "metadata": {
    "id": "HlozoHc8GI8C"
   },
   "source": [
    "- teacher forcing 용 input, target 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25f068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the data\n",
    "# load data\n",
    "    # input 과 target translation 구분\n",
    "    # target input 과 output 을 teacher forcing 입력 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f81c8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0364dc07",
   "metadata": {
    "id": "9xJ-KzkAG8zK"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "- language 가 2 개 이므로 언어별로 서로 다른 tokenizer 생성. 따라서, 2 개의 word_index 구성\n",
    "\n",
    "### 영어 input text 의 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 텍스트 데이터를 위한 Tokenizer 객체 생성 (최대 단어 수 지정)\n",
    "# 영어 텍스트 데이터를 사용하여 토크나이저 학습 수행 (단어 인덱스 구축)\n",
    "# 영어 텍스트 데이터를 시퀀스로 변환\n",
    "# 1500번째 시퀀스 출력\n",
    "# 1500번째 원본 영어 텍스트 출력\n",
    "# 1500번째 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a52d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 단어를 인덱스로 매핑한 사전 가져오기\n",
    "# 고유한 입력 토큰 수 출력\n",
    "# 사용할 단어 수 계산 (최대 어휘 크기와 실제 단어 수 + 1 중 작은 값)\n",
    "# 입력 텍스트의 최대 길이 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f90baa",
   "metadata": {
    "id": "UnAyAZK6G8zU"
   },
   "source": [
    "### 한국어 Input Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2870f3",
   "metadata": {
    "id": "RvBj6QEPG8zX"
   },
   "source": [
    "### Translation language 의 tokenizer\n",
    "- 주의 사항 : $<sos>, <eos>$때문에 special character 를 filtering 하면 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85384af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 텍스트 데이터를 위한 Tokenizer 객체 생성 (최대 단어 수 지정, 필터 비활성화)\n",
    "# 한국어 입력 및 타겟 텍스트 데이터를 사용하여 토크나이저 학습 수행 (단어 인덱스 구축)\n",
    "# 한국어 입력 텍스트 데이터를 시퀀스로 변환\n",
    "# 한국어 타겟 텍스트 데이터를 시퀀스로 변환\n",
    "# 1500번째 한국어 입력 시퀀스 출력\n",
    "# 1500번째 한국어 타겟 시퀀스 출력\n",
    "# 1500번째 한국어 입력 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력\n",
    "# 1500번째 한국어 타겟 시퀀스의 각 인덱스를 단어로 변환하여 리스트로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e11b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한국어 단어를 인덱스로 매핑한 사전 가져오기\n",
    "# 고유한 출력 토큰 수 출력\n",
    "# 사용할 단어 수 계산 (실제 단어 수 + 1)\n",
    "# 타겟 텍스트의 최대 길이 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42dabda",
   "metadata": {
    "id": "XujZjSHZG8zh"
   },
   "source": [
    "## sequence padding\n",
    "\n",
    "\n",
    "### 주의 사항\n",
    "- encoder 는 thought vector 생성 목적이므로 `pre`(default) 로 padding\n",
    "\n",
    "\n",
    "- decoder 는 teacher forcing 을 해야하므로 `post` 로 padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862f039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 영어 시퀀스를 패딩 처리하여 인코더 입력으로 변환 (최대 길이 max_len_eng로 설정)\n",
    "# 한국어 입력 시퀀스를 패딩 처리하여 디코더 입력으로 변환 (최대 길이 max_len_kor로 설정, 'post' 방식으로 패딩)\n",
    "# 한국어 타겟 시퀀스를 패딩 처리하여 디코더 타겟으로 변환 (최대 길이 max_len_kor로 설정, 'post' 방식으로 패딩)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c8f13",
   "metadata": {
    "id": "TWIdoqQGG8zk"
   },
   "source": [
    "## pretrained word embedding 값을 transfer learning\n",
    "\n",
    "- Embedding layer 의 weight 를 pre-trained model 로 초기화  \n",
    "\n",
    "\n",
    "- glove.6B 의 EMBEDDING_DIM version 사용  \n",
    "    - space 로 구분된 text file\n",
    "    - 첫번째는 word 이고 두번째 이후는 weight vector 값이다\n",
    "\n",
    "\n",
    "- word index 가 1 부터 시작하므로 0 padding 감안하여 num_words 는 len(word2idx)+1, 혹은 MAX_VOCAB_SIZE 중 작은 것 선택  \n",
    "\n",
    "\n",
    "- embedding_dict dictionary : key - word, value - embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c462eef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding(num_words, embedding_dim, tokenizer, max_vocab_size):\n",
    "    # 임베딩 사전을 저장할 딕셔너리 초기화\n",
    "    # GloVe 임베딩 파일 경로 설정\n",
    "    # GloVe 임베딩 파일 열기\n",
    "        # 파일의 각 줄에 대해 반복\n",
    "            # 두번째 값부터 마지막 값까지는 해당 단어의 임베딩 벡터 값\n",
    "    # 임베딩 매트릭스 초기화 (0으로 초기화)\n",
    "    # 토크나이저의 단어 인덱스를 사용하여 임베딩 매트릭스 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81481ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 단어 수 계산 (최대 어휘 크기와 실제 단어 수 + 1 중 작은 값)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d180b21",
   "metadata": {
    "id": "VjrgS3RWG8zy"
   },
   "source": [
    "### embedding layer 작성\n",
    "\n",
    "- encoder 와 decoder 의 Embedding layer 에 pre-trained embedding weight 를 초기값으로 load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac201d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임베딩 레이어 생성\n",
    "# 영어 단어에 대한 임베딩 매트릭스 생성\n",
    "# 임베딩 레이어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70911f29",
   "metadata": {
    "id": "0lTBcpJ7G8z2"
   },
   "source": [
    "## Build model\n",
    "\n",
    "- encoder 와 decoder 의 embedding, lstm 및 dense layer 를 training 할 목적의 model 작성  \n",
    "\n",
    "- encoder 는 decoder 에 states [h, c] 만 전달\n",
    "\n",
    "- prediction 을 위한 model 은 training model 에서 만들어진 layer 들의 weight 를 이용하여 별도 작성  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54e64ac",
   "metadata": {
    "id": "uahjsXKTG8z2"
   },
   "source": [
    "## Encoder model 작성  \n",
    "\n",
    "- Training과 Inference State 에서 모두 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d66016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 정의\n",
    "# 인코더 입력 정의 (최대 길이를 max_len_eng로 설정)\n",
    "# 사전 학습된 임베딩 레이어 사용\n",
    "# LSTM 레이어를 사용하여 인코더 출력과 상태(hidden state와 cell state) 계산\n",
    "# 인코더는 hidden state와 cell state만 디코더로 전달 (thought vector)\n",
    "# 인코더 모델 정의\n",
    "# 인코더 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0449bb",
   "metadata": {
    "id": "r4tlTKf0G8z5"
   },
   "source": [
    "## Decoder model for Teacher Forcing\n",
    "\n",
    "- Training stage 에서 만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceb6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 정의\n",
    "# 디코더 입력 정의 (최대 길이를 max_len_kor로 설정)\n",
    "# 디코더의 단어 임베딩은 사전 학습된 벡터를 사용하지 않음\n",
    "# 교사 강요(Teacher-forcing)를 위한 디코더 LSTM 정의\n",
    "# 초기 상태를 인코더의 [h, c] 상태로 설정\n",
    "# 최종 Dense 레이어 정의\n",
    "# Teacher-forcing 모델 생성\n",
    "# 모델 컴파일 및 훈련 설정\n",
    "# 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998b7d6e",
   "metadata": {
    "id": "73rTNuLZIaiy"
   },
   "source": [
    "- teacher-forcing model 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e125d72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1db512d3",
   "metadata": {
    "id": "5wbWW3D9IgZi"
   },
   "source": [
    "- teacher-forcing model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84292cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cbbbcf2",
   "metadata": {
    "id": "XyUjTEg1IkC5"
   },
   "source": [
    "- accuracy, loss 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2871837d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot some data\n",
    "# accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3049e640",
   "metadata": {
    "id": "7hQEWBi6IpGl"
   },
   "source": [
    "- save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4539733f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7e5d3e7",
   "metadata": {
    "id": "QXpQ5xqKG80E"
   },
   "source": [
    "## Make Predictions - Inference phase\n",
    "\n",
    "- prediction 을 위한 별도의 decoder model 작성  \n",
    "\n",
    "- 별로 training 없이 앞에서 train 된 weights 를 모두 재사용 한다.\n",
    "\n",
    "- decoder 는 encoder 와 분리되어 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론(Inference)용 디코더 정의\n",
    "# 디코더 LSTM의 hidden state 입력 정의 (512 차원)\n",
    "# 디코더 LSTM의 cell state 입력 정의 (512 차원)\n",
    "# 디코더 상태 입력 리스트 생성\n",
    "# 디코더의 단일 단어 입력 정의 (1차원)\n",
    "# 단일 단어 입력을 임베딩 벡터로 변환\n",
    "# 출력과 hidden states 저장\n",
    "# 새로운 디코더 상태 리스트 생성\n",
    "# 디코더 출력에 Dense 레이어 적용\n",
    "# 추론용 디코더 모델 생성\n",
    "# 추론용 디코더 모델 요약 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6e3e8d",
   "metadata": {
    "id": "HOl_sDoVI1N7"
   },
   "source": [
    "- inference 용 decoder model 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aa57ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "633066ba",
   "metadata": {
    "id": "RTLcPG9RI8dR"
   },
   "source": [
    "예측하는 동안 index를 단어를 되돌리기 위한 reverse word2idx dictionary 작성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca98d5a9",
   "metadata": {
    "id": "fUZfCBF-JKPR"
   },
   "source": [
    "### Translation Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b14a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 인코더 모델을 이용하여 입력을 상태 벡터로 인코딩\n",
    "    # 길이 1의 빈 타겟 시퀀스 생성\n",
    "    # 타겟 시퀀스의 첫 번째 단어를 시작 토큰(<sos>)으로 설정\n",
    "    # 종료 토큰(<eos>)이 디코딩에서 생성되면 루프 종료\n",
    "    # 번역문 생성\n",
    "        # 디코더 모델을 이용하여 다음 단어 예측 및 상태 업데이트\n",
    "        # argmax로 가장 확률 높은 단어 선택 (탐욕적 선택)\n",
    "        # 생성된 단어를 디코더의 다음 입력으로 사용\n",
    "        # 상태 업데이트\n",
    "# 번역 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52962055",
   "metadata": {
    "id": "Qjr59AvAJTqF"
   },
   "source": [
    "### 임의의 영어 입력을 처리하는 영한 번역 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eng_Kor_translation(txt):\n",
    "    # 입력된 영어 텍스트를 시퀀스로 변환\n",
    "    # 시퀀스를 패딩 처리하여 인코더 입력으로 변환 (최대 길이를 max_len_eng로 설정)\n",
    "    # 인코더 입력을 디코더 시퀀스로 변환하여 번역 결과 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaccc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766616e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
